{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8fc219-b1ac-4c1a-82f2-a523019ecd82",
   "metadata": {},
   "source": [
    "**Scraper for historical odds and results data from Oddsportal.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e79016-3625-4071-be10-d87d3d5a2963",
   "metadata": {},
   "source": [
    "The function scrape_oddsportal(url) in the block below, inputs a url of a page, within the results section of a league in a given year, such as 'https://www.oddsportal.com/baseball/usa/mlb-2024/results/#/page/1/', scrapes all match statistics on that page and outputs the corresponding dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab9162e-8b72-4b49-b6c0-b80bc99ed961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd\n",
    "from math import nan\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "\n",
    "# WebDriver wrapper class for managing Selenium driver lifecycle\n",
    "class Driver:\n",
    "    def __init__(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        # Uncomment the following line for headless mode\n",
    "        # options.add_argument(\"--headless\")\n",
    "        options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    def __del__(self):\n",
    "        # Ensure driver is properly quit when the object is deleted\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error quitting driver: {e}\")\n",
    "\n",
    "# Thread-local storage for WebDriver instances\n",
    "threadLocal = threading.local()\n",
    "\n",
    "def create_driver():\n",
    "    \"\"\"\n",
    "    Create or retrieve a thread-local WebDriver instance.\n",
    "    \"\"\"\n",
    "    the_driver = getattr(threadLocal, 'the_driver', None)\n",
    "    if the_driver is None:\n",
    "        the_driver = Driver()\n",
    "        setattr(threadLocal, 'the_driver', the_driver)\n",
    "    return the_driver.driver\n",
    "\n",
    "# Class to hold scraped game data\n",
    "class GameData:\n",
    "    def __init__(self):\n",
    "        self.date = []\n",
    "        self.time = []\n",
    "        self.game = []\n",
    "        self.score = []\n",
    "        self.home_odds = []\n",
    "        self.draw_odds = []\n",
    "        self.away_odds = []\n",
    "        self.country = []\n",
    "        self.league = []\n",
    "\n",
    "def generate_matches(pgSoup, defaultVal=nan):\n",
    "    \"\"\"\n",
    "    Extract match data from the parsed page source.\n",
    "\n",
    "    Args:\n",
    "        pgSoup (BeautifulSoup): Parsed page source.\n",
    "        defaultVal: Default value for missing data.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries containing match data.\n",
    "    \"\"\"\n",
    "    evtSel = {\n",
    "        'time': 'p.whitespace-nowrap', #TODO: Fix.\n",
    "        'game': 'a div:has(>a[title])',\n",
    "        'score': 'a a[title]+div:has(+a[title])',\n",
    "        'home_odds': 'a:has(a[title])~div:not(.hidden)',\n",
    "        'draw_odds': 'a:has(a[title])~div:not(.hidden)+div:nth-last-of-type(3)',\n",
    "        'away_odds': 'a:has(a[title])~div:nth-last-of-type(2)',\n",
    "    }\n",
    "\n",
    "    events = []\n",
    "    current_group = {}\n",
    "    pgDate = pgSoup.select_one('h1.title[id=\"next-matches-h1\"]')\n",
    "    if pgDate:\n",
    "        pgDate = pgDate.get_text().split(',', 1)[-1].strip()\n",
    "\n",
    "    for evt in pgSoup.select('div[set]>div:last-child'):\n",
    "        if evt.parent.select(f':scope>div:first-child+div+div'):\n",
    "            cgVals = [v.get_text(' ').strip() if v else defaultVal for v in [\n",
    "                evt.parent.select_one(s) for s in\n",
    "                [':scope>div:first-child+div>div:first-child',\n",
    "                 ':scope>div:first-child>a:nth-of-type(2):nth-last-of-type(2)',\n",
    "                 ':scope>div:first-child>a:nth-of-type(3):last-of-type']]]\n",
    "            current_group = dict(zip(['date', 'country', 'league'], cgVals))\n",
    "            if pgDate:\n",
    "                current_group['date'] = pgDate\n",
    "\n",
    "        evtRow = {'date': current_group.get('date', defaultVal)}\n",
    "\n",
    "        for k, v in evtSel.items():\n",
    "            element = evt.select_one(v)\n",
    "            text = element.get_text(' ') if element else defaultVal\n",
    "            evtRow[k] = ' '.join(text.split()) if isinstance(text, str) else text\n",
    "\n",
    "        evtTeams = evt.select('a div>a[title]')\n",
    "        evtRow['game'] = ' – '.join(a['title'] for a in evtTeams)\n",
    "        evtRow['country'] = current_group.get('country', defaultVal)\n",
    "        evtRow['league'] = current_group.get('league', defaultVal)\n",
    "\n",
    "        events.append(evtRow)\n",
    "    return events\n",
    "\n",
    "def parse_data(url):\n",
    "    \"\"\"\n",
    "    Parse match data from the given URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL to scrape.\n",
    "\n",
    "    Returns:\n",
    "        GameData: Scraped match data.\n",
    "    \"\"\"\n",
    "    browser = create_driver()\n",
    "    try:\n",
    "        browser.get(url)\n",
    "\n",
    "        # Wait for elements to load\n",
    "        WebDriverWait(browser, 10).until(EC.presence_of_all_elements_located(\n",
    "            (By.CSS_SELECTOR, \"div[set]>div:last-child a:has(a[title])~div:not(.hidden)\")))\n",
    "\n",
    "        # Scroll through the page to load all content\n",
    "        scroll_pause_time = 5\n",
    "        last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        time.sleep(5)\n",
    "        while True:\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight/2);\")\n",
    "            time.sleep(scroll_pause_time)\n",
    "            new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Parse page source\n",
    "        soup = bs(browser.page_source, \"lxml\")\n",
    "        game_data = GameData()\n",
    "        game_keys = [key for key, value in game_data.__dict__.items() if isinstance(value, list)]\n",
    "        for row in generate_matches(soup, defaultVal=nan):\n",
    "            for k in game_keys:\n",
    "                getattr(game_data, k).append(row.get(k, nan))\n",
    "\n",
    "        return game_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing data from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_oddsportal(url):\n",
    "    \"\"\"\n",
    "    Scrape match data from OddsPortal and return as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL of the OddsPortal page to scrape.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing scraped match data.\n",
    "    \"\"\"\n",
    "    pool = ThreadPool(5)  # Use thread pool for parallel scraping\n",
    "    game_data_results = pool.imap(parse_data, [url])\n",
    "\n",
    "    game_data_df_list = []\n",
    "    for game_data in game_data_results:\n",
    "        if game_data is not None:\n",
    "            try:\n",
    "                game_data_df_list.append(pd.DataFrame(game_data.__dict__))\n",
    "            except Exception as e:\n",
    "                print(f'Error tabulating game data: {e}')\n",
    "\n",
    "    try:\n",
    "        games = pd.concat(game_data_df_list, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f'Error concatenating DataFrames: {e}')\n",
    "        games = None\n",
    "\n",
    "    # Garbage collection (freeing unused memory). Could be commented.\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "    return games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739daeb-c881-4353-b743-c036dda10b17",
   "metadata": {},
   "source": [
    "The function below saves excel sheet of all tournament results of a given league and season start year to a folder like \"MLB_Data\" in cwd. If process is interrupted, rerun and it will pick up where it left off. To restart the process for another year, remove the previous output file from the designated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044931fc-ced7-4f23-8807-32fd1e11863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_tournament_results(league, year, number_of_pages):\n",
    "    \"\"\"\n",
    "    Fetches match data for a specified league and season, aggregating results from multiple pages,\n",
    "    and saves the data to an Excel file. The function is designed to handle interruptions gracefully,\n",
    "    allowing it to resume from where it left off.\n",
    "\n",
    "    Args:\n",
    "        league (str): The league identifier (e.g., 'MLB', 'NBA', 'NFL', 'NHL').\n",
    "        year (int): The starting year of the season.\n",
    "        number_of_pages (int): The total number of pages to fetch data from.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Define league-specific URL prefixes and data directories\n",
    "    league_info = {\n",
    "        'MLB': {\n",
    "            'url_prefix': f'https://www.oddsportal.com/baseball/usa/mlb-{year}/results/#/page/',\n",
    "            'data_folder': 'MLB_Data'\n",
    "        },\n",
    "        'NBA': {\n",
    "            'url_prefix': f'https://www.oddsportal.com/basketball/usa/nba-{year}-{year + 1}/results/#/page/',\n",
    "            'data_folder': 'NBA_Data'\n",
    "        },\n",
    "        'NFL': {\n",
    "            'url_prefix': f'https://www.oddsportal.com/american-football/usa/nfl-{year}-{year + 1}/results/#/page/',\n",
    "            'data_folder': 'NFL_Data'\n",
    "        },\n",
    "        'NHL': {\n",
    "            'url_prefix': f'https://www.oddsportal.com/hockey/usa/nhl-{year}-{year + 1}/results/#/page/',\n",
    "            'data_folder': 'NHL_Data'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Validate league input\n",
    "    if league not in league_info:\n",
    "        raise ValueError(f\"Unsupported league '{league}'. Supported leagues are: {', '.join(league_info.keys())}.\")\n",
    "\n",
    "    # Extract URL prefix and data folder for the specified league\n",
    "    url_prefix = league_info[league]['url_prefix']\n",
    "    data_folder = league_info[league]['data_folder']\n",
    "\n",
    "    # Ensure the data directory exists\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "    # Define the path for the Excel file\n",
    "    excel_file_path = os.path.join(data_folder, f\"{league}_{year}_results.xlsx\")\n",
    "\n",
    "    # Initialise or load existing data\n",
    "    if os.path.exists(excel_file_path):\n",
    "        all_games = pd.read_excel(excel_file_path, index_col=0)\n",
    "        start_page = (len(all_games) // 50) + 1\n",
    "    else:\n",
    "        all_games = pd.DataFrame()\n",
    "        start_page = 1\n",
    "\n",
    "    # Fetch data from each page\n",
    "    for page in range(start_page, number_of_pages + 1):\n",
    "        url = f\"{url_prefix}{page}/\"\n",
    "        try:\n",
    "            page_games_df = scrape_oddsportal(url)\n",
    "            \n",
    "            # It happens quite often that 45 out of 50 matches on a page are loaded.\n",
    "            # So we simply halt if we have 45 match statistics on a given page.\n",
    "            # In very rare cases of there being exactly 45 matches on the last page, this could skip a healthy page.\n",
    "            # TODO: Fix this.\n",
    "            if len(page_games_df)==45:\n",
    "                break\n",
    "                print(f\"Page {page} yielded 45 results and likely missed 5.\")            \n",
    "            if page_games_df is not None and not page_games_df.empty:\n",
    "                all_games = pd.concat([all_games, page_games_df], ignore_index=True)\n",
    "                # Save progress after each successful page fetch\n",
    "                all_games.to_excel(excel_file_path)\n",
    "                print(f\"Page {page} data fetched and saved successfully.\")\n",
    "            else:\n",
    "                print(f\"No data found on page {page}.\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data from page {page}: {e}\")\n",
    "            # Log the error with a timestamp\n",
    "            with open(os.path.join(data_folder, 'error_log.txt'), 'a') as log_file:\n",
    "                log_file.write(f\"{datetime.now()}: Error on page {page} - {e}\\n\")\n",
    "            # Optionally, implement a retry mechanism or continue to the next page\n",
    "            break\n",
    "#            continue\n",
    "    if page == number_of_pages:\n",
    "        print(f\"Data collection completed. Results saved to {excel_file_path}.\")\n",
    "    else:\n",
    "        print(f\"Data collection interrupted. Results, collected thus far, saved to {excel_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d651a-b566-4757-8fb0-9ab814961d97",
   "metadata": {},
   "source": [
    "Testing for 2024 season of Major League Baseball, which contains 50 pages of match results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d06e474-7b93-4695-b2f3-fa358e08c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 data fetched and saved successfully.\n",
      "Page 2 data fetched and saved successfully.\n",
      "Page 3 data fetched and saved successfully.\n",
      "Page 4 data fetched and saved successfully.\n",
      "Page 5 data fetched and saved successfully.\n",
      "Page 6 data fetched and saved successfully.\n",
      "Page 7 data fetched and saved successfully.\n",
      "Page 8 data fetched and saved successfully.\n",
      "Page 9 data fetched and saved successfully.\n",
      "Page 10 data fetched and saved successfully.\n",
      "Page 11 data fetched and saved successfully.\n",
      "Page 12 data fetched and saved successfully.\n",
      "Page 13 data fetched and saved successfully.\n",
      "Page 14 data fetched and saved successfully.\n",
      "Page 15 data fetched and saved successfully.\n",
      "Page 16 data fetched and saved successfully.\n",
      "Page 17 data fetched and saved successfully.\n",
      "Page 18 data fetched and saved successfully.\n",
      "Page 19 data fetched and saved successfully.\n",
      "Page 20 data fetched and saved successfully.\n",
      "Page 21 data fetched and saved successfully.\n",
      "Page 22 data fetched and saved successfully.\n",
      "Page 23 data fetched and saved successfully.\n",
      "Page 24 data fetched and saved successfully.\n",
      "Page 25 data fetched and saved successfully.\n",
      "Page 26 data fetched and saved successfully.\n",
      "Page 27 data fetched and saved successfully.\n",
      "Page 28 data fetched and saved successfully.\n",
      "Page 29 data fetched and saved successfully.\n",
      "Page 30 data fetched and saved successfully.\n",
      "Page 31 data fetched and saved successfully.\n",
      "Page 32 data fetched and saved successfully.\n",
      "Page 33 data fetched and saved successfully.\n",
      "Page 34 data fetched and saved successfully.\n",
      "Page 35 data fetched and saved successfully.\n",
      "Page 36 data fetched and saved successfully.\n",
      "Page 37 data fetched and saved successfully.\n",
      "Page 38 data fetched and saved successfully.\n",
      "Page 39 data fetched and saved successfully.\n",
      "Page 40 data fetched and saved successfully.\n",
      "Page 41 data fetched and saved successfully.\n",
      "Page 42 data fetched and saved successfully.\n",
      "Page 43 data fetched and saved successfully.\n",
      "Page 44 data fetched and saved successfully.\n",
      "Page 45 data fetched and saved successfully.\n",
      "Page 46 data fetched and saved successfully.\n",
      "Page 47 data fetched and saved successfully.\n",
      "Page 48 data fetched and saved successfully.\n",
      "Page 49 data fetched and saved successfully.\n",
      "Page 50 data fetched and saved successfully.\n",
      "Data collection completed. Results saved to MLB_Data\\MLB_2024_results.xlsx.\n"
     ]
    }
   ],
   "source": [
    "generate_and_save_tournament_results('MLB', 2024, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc79b879-d4f2-4c2b-a7a1-301a689b647c",
   "metadata": {},
   "source": [
    "Validating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b08344-62ef-4c23-afe1-02f7cb23a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the generated excel file into a dataframe.\n",
    "mlb_2024_df = pd.read_excel(os.path.join(os.getcwd(), \"MLB_Data\\MLB_2024_results.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37541c9-daa7-46e3-ba42-69eb398cb1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2428 entries, 0 to 2427\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  2428 non-null   int64  \n",
      " 1   date        2428 non-null   object \n",
      " 2   time        0 non-null      float64\n",
      " 3   game        2428 non-null   object \n",
      " 4   score       2428 non-null   object \n",
      " 5   home_odds   2428 non-null   object \n",
      " 6   draw_odds   0 non-null      float64\n",
      " 7   away_odds   2428 non-null   object \n",
      " 8   country     2428 non-null   object \n",
      " 9   league      2428 non-null   object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 189.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mlb_2024_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ee998-dae6-4529-86b6-554f7b019473",
   "metadata": {},
   "source": [
    "The following reformats excel files in relevant directory (here MLB_Data), and saves them in a subfolder \"Fixed\". (E.g. breaking scores like '1-3' into home_score and away_score columns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08cc962-2dec-413a-9d9f-4cab91b99c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: MLB_2024_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "current_working_directory = os.getcwd()\n",
    "raw_data_directory = os.path.join(current_working_directory, \"MLB_Data\")\n",
    "fixed_data_directory = os.path.join(current_working_directory, \"MLB_Data\", \"Fixed\")\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(fixed_data_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the raw data directory\n",
    "excel_files = os.listdir(raw_data_directory)\n",
    "\n",
    "# Process each file in the directory\n",
    "for file_index, file_name in enumerate(excel_files):\n",
    "    raw_file_path = os.path.join(raw_data_directory, file_name)  # Full path to input file\n",
    "    fixed_file_path = os.path.join(fixed_data_directory, file_name)  # Full path to output file\n",
    "\n",
    "    if os.path.isdir(raw_file_path):\n",
    "        # Skip directories if accidentally included in the list\n",
    "        continue\n",
    "\n",
    "    # Read the current Excel file\n",
    "    try:\n",
    "        raw_data_table = pd.read_excel(raw_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Initialise a DataFrame for reformatted data\n",
    "    reformatted_data = pd.DataFrame(columns=[\n",
    "        'date', 'match_type', 'home_team', 'away_team', 'result',\n",
    "        'home_score', 'away_score', 'home_odds', 'away_odds'\n",
    "    ])\n",
    "\n",
    "    # Process each row in the raw data\n",
    "    for row_index in range(len(raw_data_table)):\n",
    "        # Extract and format the date\n",
    "        raw_date = raw_data_table['date'][row_index]\n",
    "        if '-' in raw_date:\n",
    "            raw_date = raw_date.split('  -')[0]\n",
    "        formatted_date = pd.to_datetime(raw_date, format='mixed', dayfirst=True).date()\n",
    "\n",
    "        # Determine the match type\n",
    "        if 'Play Off' in raw_data_table['date'][row_index]:\n",
    "            match_type = 'play_off'\n",
    "        elif 'Pre-season' in raw_data_table['date'][row_index]:\n",
    "            match_type = 'pre_season'\n",
    "        else:\n",
    "            match_type = 'regular'\n",
    "\n",
    "        # Extract home and away teams\n",
    "        home_team, away_team = raw_data_table['game'][row_index].split(' – ')\n",
    "\n",
    "        # Extract scores, handling missing or invalid values\n",
    "        try:\n",
    "            home_score = int(raw_data_table['score'][row_index].split(' – ')[0])\n",
    "            away_score = int(raw_data_table['score'][row_index].split(' – ')[1])\n",
    "        except (ValueError, AttributeError):\n",
    "            home_score = ''\n",
    "            away_score = ''\n",
    "\n",
    "        # Determine match result\n",
    "        if isinstance(home_score, int) and isinstance(away_score, int):\n",
    "            result = 'H' if home_score > away_score else 'A'\n",
    "        else:\n",
    "            result = ''\n",
    "\n",
    "        # Extract odds, handling missing or invalid values\n",
    "        try:\n",
    "            home_odds = float(raw_data_table['home_odds'][row_index])\n",
    "            away_odds = float(raw_data_table['away_odds'][row_index])\n",
    "        except (ValueError, TypeError):\n",
    "            home_odds = ''\n",
    "            away_odds = ''\n",
    "\n",
    "        # Append the processed row to the reformatted DataFrame\n",
    "        reformatted_data.loc[len(reformatted_data)] = [\n",
    "            formatted_date, match_type, home_team, away_team, result,\n",
    "            home_score, away_score, home_odds, away_odds\n",
    "        ]\n",
    "\n",
    "    # Reset the index of the reformatted DataFrame\n",
    "    reformatted_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Save the reformatted data to the fixed data directory\n",
    "    try:\n",
    "        reformatted_data.to_excel(fixed_file_path, index=False)\n",
    "        print(f\"Processed and saved: {file_name}\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"Permission error saving file {file_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error saving file {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dea66aa-e995-4988-bc51-5a0b968b35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the formatted excel file into a dataframe.\n",
    "mlb_2024_df_formatted = pd.read_excel(os.path.join(os.getcwd(), \"MLB_Data\\Fixed\\MLB_2024_results.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091878fb-d037-45f2-95ca-b205f270dde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2428 entries, 0 to 2427\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   date        2428 non-null   datetime64[ns]\n",
      " 1   match_type  2428 non-null   object        \n",
      " 2   home_team   2428 non-null   object        \n",
      " 3   away_team   2428 non-null   object        \n",
      " 4   result      2427 non-null   object        \n",
      " 5   home_score  2427 non-null   float64       \n",
      " 6   away_score  2427 non-null   float64       \n",
      " 7   home_odds   2424 non-null   float64       \n",
      " 8   away_odds   2424 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(4), object(4)\n",
      "memory usage: 170.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mlb_2024_df_formatted.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432ed7c1-42f8-42ac-ae7a-24d3a6813690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>match_type</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>result</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>home_odds</th>\n",
       "      <th>away_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>A</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>H</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>H</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>H</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>New York Mets</td>\n",
       "      <td>H</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>Cleveland Guardians</td>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>Cleveland Guardians</td>\n",
       "      <td>New York Yankees</td>\n",
       "      <td>A</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>New York Mets</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>H</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>play_off</td>\n",
       "      <td>New York Mets</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date match_type            home_team            away_team result  \\\n",
       "0 2024-10-31   play_off     New York Yankees  Los Angeles Dodgers      A   \n",
       "1 2024-10-31   play_off     New York Yankees  Los Angeles Dodgers      H   \n",
       "2 2024-10-31   play_off     New York Yankees  Los Angeles Dodgers      A   \n",
       "3 2024-10-31   play_off  Los Angeles Dodgers     New York Yankees      H   \n",
       "4 2024-10-31   play_off  Los Angeles Dodgers     New York Yankees      H   \n",
       "5 2024-10-31   play_off  Los Angeles Dodgers        New York Mets      H   \n",
       "6 2024-10-31   play_off  Cleveland Guardians     New York Yankees      A   \n",
       "7 2024-10-31   play_off  Cleveland Guardians     New York Yankees      A   \n",
       "8 2024-10-31   play_off        New York Mets  Los Angeles Dodgers      H   \n",
       "9 2024-10-31   play_off        New York Mets  Los Angeles Dodgers      A   \n",
       "\n",
       "   home_score  away_score  home_odds  away_odds  \n",
       "0         6.0         7.0       1.67       2.27  \n",
       "1        11.0         4.0       1.74       2.15  \n",
       "2         2.0         4.0       1.67       2.27  \n",
       "3         4.0         2.0       1.75       2.14  \n",
       "4         6.0         3.0       1.82       2.05  \n",
       "5        10.0         5.0       1.66       2.30  \n",
       "6         2.0         5.0       2.13       1.76  \n",
       "7         6.0         8.0       2.05       1.81  \n",
       "8        12.0         6.0       2.13       1.76  \n",
       "9         2.0        10.0       2.15       1.75  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_2024_df_formatted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a198d96-5265-4c2a-8ba8-286f1af2be1b",
   "metadata": {},
   "source": [
    "The following code could be used to concatenate excel files in a folder and save as a single excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797d1c8-dc46-4abb-a10d-a45a183fe2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the directory\n",
    "cwd = os.getcwd()\n",
    "directory = os.path.join(cwd, \"MLB_Data\", \"Fixed\")\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter for Excel files (e.g., .xlsx and .xls)\n",
    "excel_files = [file for file in files if file.endswith(('.xlsx', '.xls'))]\n",
    "\n",
    "# Initialise an empty list to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read each Excel file and append to the list\n",
    "for file in excel_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    combined_df.sort_values(by=\"date\", ascending=False, inplace=True)\n",
    "\n",
    "    # Save the resulting DataFrame to a new Excel file\n",
    "    output_file = os.path.join(directory, \"combined_data.xlsx\")\n",
    "    combined_df.to_excel(output_file, index=False)\n",
    "    print(f\"Combined Excel file saved as: {output_file}\")\n",
    "else:\n",
    "    print(\"No Excel files found to concatenate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
